# classification-challenge
## The Challenge
>Let's say you work at an Internet Service Provider (ISP) and you've been tasked
>with improving the email filtering system for its customers. You've been
>provided with a dataset that contains information about emails, with two
>possible classifications: spam and not spam. The ISP wants you to take this
>dataset and develop a supervised machine learning (ML) model that will
>accurately detect spam emails so it can filter them out of its customers'
>inboxes.
>
>You will be creating two classification models to fit the provided data, and
>evaluate which model is more accurate at detecting spam. The models you'll
>create will be a logistic regression model and a random forest model.

## Getting Started
Before starting this assignment, make sure the user has a GitHub account. Then
take the following steps:
>
>-  Create a new repository for this project called classification-challenge.
>   **Do not add this homework assignment to an existing repository.**
>   
>-  Clone the new repository to your computer.
>
>-  Inside your local Git repository, add the starter file spam_detector.ipynb
>   from your file downloads.
>
>-  Push your changes to GitHub.
>
>### Instructions
>#### Prepare the Data
>
>This challenge consists of the following subsections:
>
>-  Split the data into training and testing sets.
>
>-  Scale the features.
>
>-  Create a logistic regression model.
>
>-  Create a random forest model.
>
>-  Evaluate the models.
>
>#### Split the Data into Training and Testing Sets
>Open the starter code notebook and then use it to complete the following steps.
>   1. Read the data from
>   https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv
>   (https://static.bcedx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)
>   into a Pandas DataFrame.
>   
>   2. In the appropriate markdown cell, make a prediction as to which model
>   you expect to do better.
>
>   3. Create the labels set ( y ) from the “spam” column, and then create the
>   features ( X ) DataFrame from the remaining columns.
>
>       NOTE
>       A value of 0 in the “spam” column means that the message is legitimate.
>       A value of 1 means that the message has been classified as spam.
>
>   4. Check the balance of the labels variable ( y ) by using the value_counts
>   function.
>
>   5. Split the data into training and testing datasets by using
>   train_test_split.
>
>#### Scale the Features
>
>   1. Create an instance of StandardScaler.
>
>   2. Fit the Standard Scaler with the training data.
>
>   3. Scale the training and testing features DataFrames using the transform
>   function.
>
>#### Create a Logistic Regression Model
>Employ your knowledge of logistic regression to complete the following steps:
>
>   1. Fit a logistic regression model by using the scaled training data
>   (X_train_scaled and y_train). Set the random_state argument to 1.
>
>   2.  Save the predictions on the testing data labels by using the testing
>   feature data ( X_test_scaled ) and the fitted model.
>
>   3. Evaluate the model’s performance by calculating the accuracy score of
>   the model.
>
>#### Create a Random Forest Model
>Employ your knowledge of the random forest classifier to complete the following
>steps:
>
>   1. Fit a random forest classifier model by using the scaled training data
>   ( X_train_scaled and y_train ).
>
>   2. Save the predictions on the testing data labels by using the testing
>   feature data ( X_test_scaled ) and the fitted model.
>
>   3. Evaluate the model’s performance by calculating the accuracy score of the
>   model.
>
>#### Evaluate the Models
>In the appropriate markdown cell, answer the following questions:
>
>   1. Which model performed better?
>
>   2. How does that compare to your prediction?
>
## Sources
The starter codes were obtained in February 2024 from the instructional staff of
the OSU AI Bootcamp and were generated by edX Boot Camps LLC.
## Collaborators
Although this project was done individually, the skillset used to complete this 
assignment is a culmination of knowledge learned in the classroom setting which
includes lecture materials, example programming from instructors, interactive
dialogue in group settings among fellow students, independent internet research,
and some general programming guidance from sources such as CoPilot and ChatGPT. 